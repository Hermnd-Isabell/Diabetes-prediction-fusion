#!/usr/bin/env python3
"""
å‡æ•°æ®é€‚é…å™¨ - å°†å‡æ•°æ®ç”Ÿæˆå™¨ä¸ç°æœ‰è®­ç»ƒç³»ç»Ÿç»“åˆ

è¿™ä¸ªæ¨¡å—å…è®¸ä½ ä½¿ç”¨ç°æœ‰çš„è®­ç»ƒå™¨å’Œmainå‡½æ•°æ¥è®­ç»ƒæ¨¡å‹ï¼Œ
ä½†ä½¿ç”¨å‡æ•°æ®è€Œä¸æ˜¯çœŸå®æ•°æ®ï¼Œéå¸¸é€‚åˆæµ‹è¯•å’ŒéªŒè¯ã€‚
"""

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
import yaml
import argparse

# å¯¼å…¥ç°æœ‰çš„è®­ç»ƒç³»ç»Ÿ
from trainers.enhanced_trainer import EnhancedTrainer
from models.attention_models import AttentionMultimodal
from models.Baseline import ConcatFusion, EnsembleFusion, BaselineMultimodal
from models.tft_models import TFTMultimodal
from models.enhanced_mmtm_models import EnhancedMMTMFusion

# å¯¼å…¥å‡æ•°æ®ç”Ÿæˆå™¨
from fake_data_generator import FakeDataGenerator


def create_fake_dataset(num_samples=100, num_scans=3, num_wavelengths=1000, num_features=10, num_classes=2):
    """åˆ›å»ºå‡æ•°æ®é›†"""
    data = []
    generator = FakeDataGenerator()
    
    for i in range(num_samples):
        # ç”Ÿæˆå…‰è°±æ•°æ®
        spectra = generator.generate_spectral_data(1, num_scans, num_wavelengths)[0]  # å½¢çŠ¶: (num_scans, num_wavelengths)
        
        # ç”Ÿæˆè¡¨æ ¼æ•°æ®
        tabular = generator.generate_tabular_data(1, num_features)[0]
        
        # ç”Ÿæˆæ ‡ç­¾
        label = generator.generate_labels(1, num_classes)[0].item()
        
        # ç”Ÿæˆmaskï¼ˆæ‰€æœ‰æ‰«æéƒ½æœ‰æ•ˆï¼‰
        mask = torch.ones(num_scans, dtype=torch.bool)
        
        data.append({
            'spectra': spectra,
            'tabular': tabular,
            'label': label,
            'mask': mask
        })
    
    return data


class FakeDataAdapter:
    """
    å‡æ•°æ®é€‚é…å™¨ç±»
    
    å°†å‡æ•°æ®ç”Ÿæˆå™¨ä¸ç°æœ‰çš„è®­ç»ƒç³»ç»Ÿæ— ç¼ç»“åˆ
    """
    
    def __init__(self, config_path: str = None):
        """
        åˆå§‹åŒ–é€‚é…å™¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        """
        self.config_path = config_path
        self.config = self._load_config() if config_path else self._get_default_config()
        
    def _load_config(self) -> dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        with open(self.config_path, "r", encoding='utf-8') as f:
            return yaml.safe_load(f)
    
    def _get_default_config(self) -> dict:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            "data": {
                "use_fake_data": True,
                "num_samples": 200,
                "num_scans": 3,
                "num_wavelengths": 1000,
                "num_features": 10,
                "num_classes": 2,
                "train_ratio": 0.7,
                "val_ratio": 0.15,
                "test_ratio": 0.15
            },
            "model": {
                "name": "AttentionMultimodal",
                "num_classes": 2,
                "spec_emb": 256,
                "tab_emb": 128,
                "fusion": "enhanced_cross"
            },
            "train": {
                "batch_size": 8,
                "epochs": 20,
                "lr": 0.001,
                "weight_decay": 1e-4,
                "early_stopping_patience": 10,
                "save_dir": "fake_data_results"
            },
            "visualization": {
                "enable": True
            },
            "interpretability": {
                "enable": True
            }
        }
    
    def prepare_fake_data(self) -> Tuple[DataLoader, DataLoader, DataLoader, dict]:
        """
        å‡†å¤‡å‡æ•°æ®
        
        Returns:
            (train_loader, val_loader, test_loader, dataset_info)
        """
        print("ğŸ“Š å‡†å¤‡å‡æ•°æ®...")
        
        # è·å–æ•°æ®é…ç½®
        data_cfg = self.config["data"]
        
        # åˆ›å»ºå‡æ•°æ®é›†
        dataset = create_fake_dataset(
            num_samples=data_cfg["num_samples"],
            num_scans=data_cfg["num_scans"],
            num_wavelengths=data_cfg["num_wavelengths"],
            num_features=data_cfg["num_features"],
            num_classes=data_cfg["num_classes"]
        )
        
        print(f"âœ… å‡æ•°æ®é›†åˆ›å»ºå®Œæˆ: {len(dataset)} ä¸ªæ ·æœ¬")
        
        # æ•°æ®åˆ’åˆ†
        train_ratio = data_cfg["train_ratio"]
        val_ratio = data_cfg["val_ratio"]
        test_ratio = data_cfg["test_ratio"]
        
        # ç¡®ä¿æ¯”ä¾‹å’Œä¸º1
        total_ratio = train_ratio + val_ratio + test_ratio
        train_ratio /= total_ratio
        val_ratio /= total_ratio
        test_ratio /= total_ratio
        
        train_size = int(train_ratio * len(dataset))
        val_size = int(val_ratio * len(dataset))
        test_size = len(dataset) - train_size - val_size
        
        train_set, val_set, test_set = torch.utils.data.random_split(
            dataset, [train_size, val_size, test_size],
            generator=torch.Generator().manual_seed(42)
        )
        
        print(f"ğŸ“Š æ•°æ®åˆ’åˆ†: è®­ç»ƒ={len(train_set)}, éªŒè¯={len(val_set)}, æµ‹è¯•={len(test_set)}")
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        batch_size = self.config["train"]["batch_size"]
        train_loader = DataLoader(
            train_set, batch_size=batch_size, shuffle=True, collate_fn=self._collate_fn
        )
        val_loader = DataLoader(
            val_set, batch_size=batch_size, shuffle=False, collate_fn=self._collate_fn
        )
        test_loader = DataLoader(
            test_set, batch_size=batch_size, shuffle=False, collate_fn=self._collate_fn
        )
        
        # æ•°æ®é›†ä¿¡æ¯
        dataset_info = {
            'tab_dim': data_cfg["num_features"],
            'spec_len': data_cfg["num_wavelengths"],
            'num_classes': data_cfg["num_classes"],
            'class_distribution': {0: len(dataset)//2, 1: len(dataset)//2}  # å‡æ•°æ®å‡åŒ€åˆ†å¸ƒ
        }
        
        print(f"ğŸ“Š æ•°æ®é›†ä¿¡æ¯:")
        print(f"   â€¢ è¡¨æ ¼ç‰¹å¾ç»´åº¦: {dataset_info['tab_dim']}")
        print(f"   â€¢ å…‰è°±é•¿åº¦: {dataset_info['spec_len']}")
        print(f"   â€¢ ç±»åˆ«æ•°: {dataset_info['num_classes']}")
        print(f"   â€¢ ç±»åˆ«åˆ†å¸ƒ: {dataset_info['class_distribution']}")
        
        return train_loader, val_loader, test_loader, dataset_info
    
    def _collate_fn(self, batch):
        """æ‰¹å¤„ç†å‡½æ•°"""
        spectra = torch.stack([item['spectra'] for item in batch])  # å½¢çŠ¶: (batch_size, 1, num_scans, num_wavelengths)
        spectra = spectra.squeeze(1)  # å»æ‰ç¬¬1ç»´ï¼Œå˜æˆ (batch_size, num_scans, num_wavelengths)
        tabular = torch.stack([item['tabular'] for item in batch])
        labels = torch.tensor([item['label'] for item in batch])
        masks = torch.stack([item['mask'] for item in batch])
        
        return {
            'spectra': spectra,
            'tabular': tabular,
            'label': labels,
            'mask': masks
        }
    
    def build_model(self, dataset_info: dict) -> torch.nn.Module:
        """
        æ„å»ºæ¨¡å‹
        
        Args:
            dataset_info: æ•°æ®é›†ä¿¡æ¯
            
        Returns:
            æ„å»ºçš„æ¨¡å‹
        """
        model_name = self.config["model"]["name"]
        num_classes = self.config["model"]["num_classes"]
        
        print(f"ğŸ—ï¸  æ„å»ºæ¨¡å‹: {model_name}")
        
        if model_name == "AttentionMultimodal":
            fusion_cfg = self.config["model"].get("fusion", "enhanced_cross")
            fusion_map = {
                "cross": "enhanced_cross",
                "enhanced_cross": "enhanced_cross",
                "concat": "concat"
            }
            fusion_type = fusion_map.get(fusion_cfg, fusion_cfg)
            
            return AttentionMultimodal(
                spec_embedding_dim=self.config["model"].get("spec_emb", 256),
                tab_embedding_dim=self.config["model"].get("tab_emb", 128),
                num_classes=num_classes,
                fusion_type=fusion_type,
                tab_dim=dataset_info['tab_dim']
            )
        
        elif model_name == "ConcatFusion":
            return ConcatFusion(
                spec_dim=self.config["model"].get("spec_emb", 256),
                clin_dim=self.config["model"].get("tab_emb", 128)
            )
        
        elif model_name == "EnsembleFusion":
            return EnsembleFusion(
                spec_dim=self.config["model"].get("spec_emb", 256),
                clin_dim=self.config["model"].get("tab_emb", 128)
            )
        
        elif model_name == "TFTMultimodal":
            return TFTMultimodal(
                tab_dim=dataset_info['tab_dim'],
                spec_len=dataset_info['spec_len'],
                spec_emb=self.config["model"].get("spec_emb", 256),
                tab_emb=self.config["model"].get("tab_emb", 128),
                num_classes=num_classes
            )
        
        elif model_name == "EnhancedMMTMFusion":
            return EnhancedMMTMFusion(
                spec_embedding_dim=self.config["model"].get("spec_emb", 256),
                tab_embedding_dim=self.config["model"].get("tab_emb", 128),
                num_classes=num_classes,
                mmtm_bottleneck=self.config["model"].get("mmtm_bottleneck", 128),
                num_attention_heads=self.config["model"].get("num_attention_heads", 8),
                fusion_strategy=self.config["model"].get("fusion_strategy", "hierarchical"),
                enable_uncertainty=self.config["model"].get("enable_uncertainty", True)
            )
        
        elif model_name == "BaselineMultimodal":
            fusion_type = self.config["model"].get("fusion_type", "concat")
            return BaselineMultimodal(
                spec_embedding_dim=self.config["model"].get("spec_emb", 256),
                tab_embedding_dim=self.config["model"].get("tab_emb", 128),
                num_classes=num_classes,
                fusion_type=fusion_type
            )
        
        else:
            raise ValueError(f"âŒ æœªçŸ¥æ¨¡å‹åç§°: {model_name}")
    
    def train_single_model(
        self,
        train_loader: DataLoader,
        val_loader: DataLoader,
        test_loader: DataLoader,
        dataset_info: dict,
        model_name: str = None
    ) -> EnhancedTrainer:
        """
        è®­ç»ƒå•ä¸ªæ¨¡å‹
        
        Args:
            train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
            val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
            test_loader: æµ‹è¯•æ•°æ®åŠ è½½å™¨
            dataset_info: æ•°æ®é›†ä¿¡æ¯
            model_name: æ¨¡å‹åç§°ï¼ˆå¯é€‰ï¼Œè¦†ç›–é…ç½®ä¸­çš„åç§°ï¼‰
            
        Returns:
            è®­ç»ƒå¥½çš„è®­ç»ƒå™¨
        """
        # ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹åç§°æˆ–é…ç½®ä¸­çš„åç§°
        if model_name:
            self.config["model"]["name"] = model_name
        
        # æ„å»ºæ¨¡å‹
        model = self.build_model(dataset_info)
        
        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = EnhancedTrainer(
            model=model,
            model_name=self.config["model"]["name"],
            device=torch.device("cuda" if torch.cuda.is_available() else "cpu"),
            lr=float(self.config["train"]["lr"]),
            weight_decay=float(self.config["train"]["weight_decay"]),
            save_dir=self.config["train"]["save_dir"],
            enable_visualization=bool(self.config.get("visualization", {}).get("enable", True)),
            enable_interpretability=bool(self.config.get("interpretability", {}).get("enable", True))
        )
        
        # æ‰“å°æ¨¡å‹ä¿¡æ¯
        model_summary = trainer.get_model_summary()
        print(f"\nğŸ“Š æ¨¡å‹æ‘˜è¦:")
        print(f"   â€¢ æ¨¡å‹åç§°: {model_summary['model_name']}")
        print(f"   â€¢ æ€»å‚æ•°æ•°: {model_summary['total_parameters']:,}")
        print(f"   â€¢ å¯è®­ç»ƒå‚æ•°: {model_summary['trainable_parameters']:,}")
        print(f"   â€¢ æ¨¡å‹å¤§å°: {model_summary['model_size_mb']:.2f} MB")
        print(f"   â€¢ è®¾å¤‡: {model_summary['device']}")
        
        # è®­ç»ƒæ¨¡å‹
        training_result = trainer.train(
            train_loader=train_loader,
            val_loader=val_loader,
            epochs=self.config["train"]["epochs"],
            early_stopping_patience=self.config["train"]["early_stopping_patience"],
            save_best=True
        )
        
        # æµ‹è¯•æ¨¡å‹
        print(f"\nğŸ” æµ‹è¯• {self.config['model']['name']}...")
        test_result = trainer.evaluate(test_loader, generate_plots=True)
        
        # ä¿å­˜ç»“æœ
        results_path = trainer.save_dir / "results.json"
        with open(results_path, 'w', encoding='utf-8') as f:
            import json
            json.dump({
                'model_name': self.config["model"]["name"],
                'training_result': training_result,
                'test_result': {
                    'metrics': test_result['metrics'],
                    'classification_report': test_result['classification_report']
                },
                'model_summary': model_summary
            }, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… {self.config['model']['name']} è®­ç»ƒå®Œæˆ!")
        print(f"ğŸ“Š æµ‹è¯•AUC: {test_result['metrics']['auc']:.4f}")
        print(f"ğŸ“Š æµ‹è¯•å‡†ç¡®ç‡: {test_result['metrics']['acc']:.4f}")
        
        return trainer
    
    def train_all_models(
        self,
        train_loader: DataLoader,
        val_loader: DataLoader,
        test_loader: DataLoader,
        dataset_info: dict
    ) -> list:
        """
        è®­ç»ƒæ‰€æœ‰æ¨¡å‹å¹¶è¿›è¡Œæ¯”è¾ƒ
        
        Args:
            train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
            val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
            test_loader: æµ‹è¯•æ•°æ®åŠ è½½å™¨
            dataset_info: æ•°æ®é›†ä¿¡æ¯
            
        Returns:
            è®­ç»ƒå™¨åˆ—è¡¨
        """
        print(f"\nğŸš€ å¼€å§‹è®­ç»ƒæ‰€æœ‰æ¨¡å‹...")
        print("=" * 60)
        
        # å®šä¹‰è¦è®­ç»ƒçš„æ¨¡å‹
        models_to_train = self.config.get("models_to_train", [
            "AttentionMultimodal",
            "ConcatFusion", 
            "TFTMultimodal",
            "EnhancedMMTMFusion",
            "BaselineMultimodal"
        ])
        
        trainers = []
        
        for model_name in models_to_train:
            print(f"\n{'='*20} è®­ç»ƒ {model_name} {'='*20}")
            
            try:
                trainer = self.train_single_model(
                    train_loader=train_loader,
                    val_loader=val_loader,
                    test_loader=test_loader,
                    dataset_info=dataset_info,
                    model_name=model_name
                )
                trainers.append(trainer)
                
            except Exception as e:
                print(f"âŒ è®­ç»ƒ {model_name} å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                continue
        
        # æ¨¡å‹æ¯”è¾ƒ
        if len(trainers) > 1:
            print(f"\nğŸ”„ å¼€å§‹æ¨¡å‹æ¯”è¾ƒ...")
            from trainers.enhanced_trainer import compare_models
            comparison_result = compare_models(
                trainers=trainers,
                test_loader=test_loader,
                save_dir=self.config["train"]["save_dir"] + "/comparison"
            )
            
            print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {comparison_result['best_model']}")
            print(f"ğŸ“Š æœ€ä½³AUC: {comparison_result['best_auc']:.4f}")
            
            # ä¿å­˜æ¯”è¾ƒç»“æœ
            comparison_path = Path(self.config["train"]["save_dir"]) / "comparison" / "comparison_summary.json"
            comparison_path.parent.mkdir(parents=True, exist_ok=True)
            with open(comparison_path, 'w', encoding='utf-8') as f:
                import json
                json.dump({
                    'best_model': comparison_result['best_model'],
                    'best_auc': comparison_result['best_auc'],
                    'metrics_comparison': comparison_result['metrics'].to_dict()
                }, f, indent=2, ensure_ascii=False)
        
        return trainers


def main():
    """ä¸»å‡½æ•° - ä½¿ç”¨å‡æ•°æ®è®­ç»ƒæ¨¡å‹"""
    parser = argparse.ArgumentParser(description="ä½¿ç”¨å‡æ•°æ®è®­ç»ƒå¤šæ¨¡æ€æ¨¡å‹")
    parser.add_argument("--config", type=str, default=None, help="é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰")
    parser.add_argument("--model", type=str, default=None, help="æŒ‡å®šå•ä¸ªæ¨¡å‹åç§°")
    parser.add_argument("--train-all", action="store_true", help="è®­ç»ƒæ‰€æœ‰æ¨¡å‹")
    parser.add_argument("--samples", type=int, default=200, help="å‡æ•°æ®æ ·æœ¬æ•°é‡")
    parser.add_argument("--epochs", type=int, default=20, help="è®­ç»ƒè½®æ•°")
    parser.add_argument("--batch-size", type=int, default=8, help="æ‰¹æ¬¡å¤§å°")
    
    args = parser.parse_args()
    
    print("ğŸš€ ä½¿ç”¨å‡æ•°æ®è®­ç»ƒå¤šæ¨¡æ€æ¨¡å‹")
    print("=" * 60)
    
    # åˆ›å»ºé€‚é…å™¨
    adapter = FakeDataAdapter(config_path=args.config)
    
    # å¦‚æœé€šè¿‡å‘½ä»¤è¡Œå‚æ•°æŒ‡å®šäº†å‚æ•°ï¼Œæ›´æ–°é…ç½®
    if args.samples:
        adapter.config["data"]["num_samples"] = args.samples
    if args.epochs:
        adapter.config["train"]["epochs"] = args.epochs
    if args.batch_size:
        adapter.config["train"]["batch_size"] = args.batch_size
    
    print(f"ğŸ“‹ é…ç½®ä¿¡æ¯:")
    print(f"   â€¢ æ ·æœ¬æ•°é‡: {adapter.config['data']['num_samples']}")
    print(f"   â€¢ è®­ç»ƒè½®æ•°: {adapter.config['train']['epochs']}")
    print(f"   â€¢ æ‰¹æ¬¡å¤§å°: {adapter.config['train']['batch_size']}")
    print(f"   â€¢ ä¿å­˜ç›®å½•: {adapter.config['train']['save_dir']}")
    
    # å‡†å¤‡æ•°æ®
    train_loader, val_loader, test_loader, dataset_info = adapter.prepare_fake_data()
    
    if args.train_all:
        # è®­ç»ƒæ‰€æœ‰æ¨¡å‹
        trainers = adapter.train_all_models(train_loader, val_loader, test_loader, dataset_info)
    else:
        # è®­ç»ƒå•ä¸ªæ¨¡å‹
        model_name = args.model or adapter.config["model"]["name"]
        trainer = adapter.train_single_model(
            train_loader=train_loader,
            val_loader=val_loader,
            test_loader=test_loader,
            dataset_info=dataset_info,
            model_name=model_name
        )
    
    print(f"\nğŸ‰ è®­ç»ƒå®Œæˆ!")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {adapter.config['train']['save_dir']}")


if __name__ == "__main__":
    main()
