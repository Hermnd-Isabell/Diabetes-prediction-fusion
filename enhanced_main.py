#!/usr/bin/env python3
"""
å¢å¼ºç‰ˆä¸»è®­ç»ƒè„šæœ¬ - æ”¯æŒå››ä¸ªæ¨¡å‹å¹¶åŒ…å«ä¸°å¯Œçš„å¯è§†åŒ–å’Œå¯è§£é‡Šæ€§åˆ†æ

æ”¯æŒçš„æ¨¡å‹:
- AttentionMultimodal (æ³¨æ„åŠ›æœºåˆ¶)
- Baseline (ConcatFusion, EnsembleFusion)  
- TFTMultimodal (æ—¶åºèåˆTransformer)

åŠŸèƒ½ç‰¹æ€§:
- å¤šæ¨¡å‹è®­ç»ƒå’Œå¯¹æ¯”
- ä¸°å¯Œçš„å¯è§†åŒ–å±•ç¤º
- å¯è§£é‡Šæ€§åˆ†æ
- æ€§èƒ½æŒ‡æ ‡è·Ÿè¸ª
- æ¨¡å‹ä¿å­˜å’ŒåŠ è½½
"""

import argparse
import yaml
import torch
import numpy as np
import pandas as pd
from pathlib import Path
from torch.utils.data import DataLoader, random_split
import warnings

# å¯¼å…¥æ•°æ®é›†å’Œè®­ç»ƒå™¨
from datasets.raman_dataset import RamanDataset, collate_fn, preprocess_spectrum
from datasets.embedding_dataset import EmbeddingMultimodalDataset, embedding_collate_fn
from trainers.enhanced_trainer import EnhancedTrainer, compare_models

# å¯¼å…¥æ‰€æœ‰æ¨¡å‹
from models.Baseline import SpectraEncoder, TabularEncoder, ConcatFusion, EnsembleFusion
from models.attention_models import AttentionMultimodal
from models.tft_models import TFTMultimodal
from models.enhanced_mmtm_models import EnhancedMMTMFusion

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings('ignore')


def load_config(config_path: str) -> dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    with open(config_path, "r", encoding='utf-8') as f:
        return yaml.safe_load(f)


def build_model(cfg: dict, tab_dim: int, spec_len: int) -> torch.nn.Module:
    """
    æ ¹æ®é…ç½®æ„å»ºæ¨¡å‹
    
    Args:
        cfg: é…ç½®å­—å…¸
        tab_dim: è¡¨æ ¼ç‰¹å¾ç»´åº¦
        spec_len: å…‰è°±é•¿åº¦
    
    Returns:
        æ„å»ºçš„æ¨¡å‹
    """
    model_name = cfg["model"]["name"]
    num_classes = cfg["model"]["num_classes"]
    
    print(f"[BUILD] æ„å»ºæ¨¡å‹: {model_name}")

    # æ ¹æ®å½“å‰æ˜¯å¦ä½¿ç”¨ embedding æ¨¡å¼ï¼Œç¡®å®šå„æ¨¡æ€ embedding ç»´åº¦
    use_embedding = cfg.get("data", {}).get("use_embedding", False)
    if use_embedding:
        # åœ¨ embedding æ¨¡å¼ä¸‹ï¼Œç›´æ¥ä½¿ç”¨æ•°æ®é›†ä¸­å®é™…çš„ embedding ç»´åº¦
        spec_emb_dim = spec_len
        tab_emb_dim = tab_dim
    else:
        # åœ¨ raw æ¨¡å¼ä¸‹ï¼Œä½¿ç”¨é…ç½®ä¸­çš„é»˜è®¤ embedding ç»´åº¦
        spec_emb_dim = cfg["model"].get("spec_emb", 256)
        tab_emb_dim = cfg["model"].get("tab_emb", 128)
    
    if model_name == "Spectra-only":
        return SpectraEncoder(input_dim=spec_len, hidden_dim=256)
    
    elif model_name == "Clinical-only":
        return TabularEncoder(input_dim=tab_dim, hidden_dim=128)
    
    elif model_name == "ConcatFusion":
        return ConcatFusion(spec_dim=spec_emb_dim, clin_dim=tab_emb_dim)
    
    elif model_name == "EnsembleFusion":
        return EnsembleFusion(spec_dim=spec_emb_dim, clin_dim=tab_emb_dim)
    
    elif model_name == "BaselineMultimodal":
        # BaselineMultimodal æ˜¯ä¸€ä¸ªåŒ…è£…ç±»ï¼Œéœ€è¦æŒ‡å®š fusion_type
        from models.Baseline import BaselineMultimodal
        fusion_type = cfg["model"].get("fusion_type", "concat")
        return BaselineMultimodal(
            spec_embedding_dim=spec_emb_dim,
            tab_embedding_dim=tab_emb_dim,
            num_classes=num_classes,
            fusion_type=fusion_type
        )
    
    elif model_name == "AttentionMultimodal":
        # å…¼å®¹æ—§é…ç½®ä¸­çš„ fusion å–å€¼
        fusion_cfg = cfg["model"].get("fusion", "enhanced_cross")
        fusion_map = {
            "cross": "enhanced_cross",
            "enhanced_cross": "enhanced_cross",
            "concat": "concat"
        }
        fusion_type = fusion_map.get(fusion_cfg, fusion_cfg)

        return AttentionMultimodal(
            spec_embedding_dim=spec_emb_dim,
            tab_embedding_dim=tab_emb_dim,
            num_classes=num_classes,
            fusion_type=fusion_type,
            tab_dim=tab_dim
        )
    
    elif model_name == "TFTMultimodal":
        return TFTMultimodal(
            tab_dim=tab_dim,
            spec_len=spec_len,
            spec_emb=spec_emb_dim,
            tab_emb=tab_emb_dim,
            num_classes=num_classes
        )
    
    
    elif model_name == "EnhancedMMTM":
        return EnhancedMMTMFusion(
            spec_embedding_dim=spec_emb_dim,
            tab_embedding_dim=tab_emb_dim,
            num_classes=num_classes,
            mmtm_bottleneck=cfg["model"].get("mmtm_bottleneck", 128),
            num_attention_heads=cfg["model"].get("num_attention_heads", 8),
            fusion_strategy=cfg["model"].get("fusion_strategy", "hierarchical"),
            enable_uncertainty=cfg["model"].get("enable_uncertainty", True)
        )
    
    else:
        raise ValueError(f"[ERROR] æœªçŸ¥æ¨¡å‹åç§°: {model_name}")


def prepare_data(cfg: dict) -> tuple:
    """
    å‡†å¤‡æ•°æ®é›†
    
    Args:
        cfg: é…ç½®å­—å…¸
    
    Returns:
        (train_loader, val_loader, test_loader, dataset_info)
    """
    print("[DATA] å‡†å¤‡æ•°æ®é›†...")
    
    use_embedding = cfg["data"].get("use_embedding", False)

    if use_embedding:
        # -----------------------------
        # embedding æ¨¡å¼ï¼šä» CSV åŠ è½½å·²å¯¹é½çš„å•æ¨¡æ€ embedding
        # -----------------------------
        from multimodal.embedding_loader import (
            load_spectrum_embedding,
            load_clinical_embedding,
            align_by_patient_id,
        )

        spec_path = cfg["data"]["spectrum_embedding_path"]
        clin_path = cfg["data"]["clinical_embedding_path"]

        print(f"[DATA] ä½¿ç”¨ embedding æ¨¡å¼åŠ è½½æ•°æ®")
        print(f"   - å…‰è°± embedding: {spec_path}")
        print(f"   - ä¸´åºŠ embedding: {clin_path}")

        spectrum_dict = load_spectrum_embedding(spec_path)
        clinical_dict = load_clinical_embedding(clin_path)
        aligned = align_by_patient_id(spectrum_dict, clinical_dict)

        # è·å–æ¨¡æ€ dropout é…ç½®ï¼ˆä»…åœ¨è®­ç»ƒé›†ä½¿ç”¨ï¼‰
        dropout_cfg = cfg["train"].get("modality_dropout", {"spectra": 0.0, "clinical": 0.0})
        
        # åŸºäº split å­—æ®µæ„å»ºä¸‰ä¸ª Dataset
        # è®­ç»ƒé›†å¯ä»¥ä½¿ç”¨ dropoutï¼ŒéªŒè¯/æµ‹è¯•é›†ä¸¥ç¦ dropout
        train_set = EmbeddingMultimodalDataset(
            aligned, split="train", dropout_config=dropout_cfg
        )
        val_set = EmbeddingMultimodalDataset(
            aligned, split="val", dropout_config={"spectra": 0.0, "clinical": 0.0}
        )
        test_set = EmbeddingMultimodalDataset(
            aligned, split="test", dropout_config={"spectra": 0.0, "clinical": 0.0}
        )
        
        # æ‰“å° dropout é…ç½®ä¿¡æ¯
        if dropout_cfg.get("spectra", 0.0) > 0 or dropout_cfg.get("clinical", 0.0) > 0:
            print(f"[DATA] æ¨¡æ€ Dropout é…ç½®:")
            print(f"   - å…‰è°± dropout æ¦‚ç‡: {dropout_cfg.get('spectra', 0.0):.2f}")
            print(f"   - ä¸´åºŠ dropout æ¦‚ç‡: {dropout_cfg.get('clinical', 0.0):.2f}")
            print(f"   - æ³¨æ„: Dropout ä»…åœ¨è®­ç»ƒé›†ç”Ÿæ•ˆï¼ŒéªŒè¯/æµ‹è¯•é›†ä¸ä½¿ç”¨")

        print(f"[DATA] Embedding æ•°æ®åˆ’åˆ†: è®­ç»ƒ={len(train_set)}, éªŒè¯={len(val_set)}, æµ‹è¯•={len(test_set)}")

        batch_size = cfg["train"]["batch_size"]
        train_loader = DataLoader(
            train_set, batch_size=batch_size, shuffle=True, collate_fn=embedding_collate_fn
        )
        val_loader = DataLoader(
            val_set, batch_size=batch_size, shuffle=False, collate_fn=embedding_collate_fn
        )
        test_loader = DataLoader(
            test_set, batch_size=batch_size, shuffle=False, collate_fn=embedding_collate_fn
        )

        # ä»ä»»æ„éç©ºå­é›†æ¨æ–­ç»´åº¦ä¿¡æ¯
        ref_items = (
            train_set.items if len(train_set) > 0
            else (val_set.items if len(val_set) > 0 else test_set.items)
        )
        if not ref_items:
            raise ValueError("å¯¹é½åçš„ embedding æ•°æ®ä¸ºç©ºï¼Œæ— æ³•æ„å»ºæ•°æ®é›†")

        tab_dim = ref_items[0]["tabular"].shape[0]
        spec_len = ref_items[0]["spectra"].shape[0]
        labels_all = [it["label"] for it in ref_items]

        dataset_info = {
            "tab_dim": tab_dim,
            "spec_len": spec_len,
            "num_classes": len(set(labels_all)),
            "class_distribution": pd.Series(labels_all).value_counts().to_dict(),
        }

        print(f"[DATA] Embedding æ•°æ®é›†ä¿¡æ¯:")
        print(f"   - è¡¨æ ¼ç‰¹å¾ç»´åº¦ (Dc): {dataset_info['tab_dim']}")
        print(f"   - å…‰è°±ç‰¹å¾ç»´åº¦ (Ds): {dataset_info['spec_len']}")
        print(f"   - ç±»åˆ«æ•°: {dataset_info['num_classes']}")
        print(f"   - ç±»åˆ«åˆ†å¸ƒ: {dataset_info['class_distribution']}")

        return train_loader, val_loader, test_loader, dataset_info

    # -----------------------------
    # åŸå§‹ raw æ¨¡å¼ï¼šRamanDataset + å…‰è°±åºåˆ—
    # -----------------------------
    # æ•°æ®è·¯å¾„
    spectra_csv = cfg["data"]["spectra_csv"]
    clinical_csv = cfg["data"]["clinical_csv"]
    
    # è¯»å–å…‰è°±æ•°æ®è·å–æ³¢é•¿åˆ—
    spectra_df = pd.read_csv(spectra_csv, sep=None, engine="python")
    wave_cols = [c for c in spectra_df.columns if c not in ["Sample", "Group"]]
    
    # åˆ›å»ºæ•°æ®é›†
    dataset = RamanDataset(
        spectra_csv=spectra_csv,
        clinical_csv=clinical_csv,
        wave_cols=wave_cols,
        label_col=cfg["data"].get("label_col", "Group"),
        preprocess_fn=preprocess_spectrum,
        min_scans=1,
        max_scans=cfg["data"].get("max_scans", 180),
    )
    
    print(f"[OK] æ•°æ®é›†åŠ è½½å®Œæˆ: {len(dataset)} ä¸ªæ ·æœ¬")
    
    # æ•°æ®åˆ’åˆ†
    train_ratio = cfg["data"].get("train_ratio", 0.7)
    val_ratio = cfg["data"].get("val_ratio", 0.15)
    test_ratio = cfg["data"].get("test_ratio", 0.15)
    
    # ç¡®ä¿æ¯”ä¾‹å’Œä¸º1
    total_ratio = train_ratio + val_ratio + test_ratio
    train_ratio /= total_ratio
    val_ratio /= total_ratio
    test_ratio /= total_ratio
    
    train_size = int(train_ratio * len(dataset))
    val_size = int(val_ratio * len(dataset))
    test_size = len(dataset) - train_size - val_size
    
    train_set, val_set, test_set = random_split(
        dataset, [train_size, val_size, test_size],
        generator=torch.Generator().manual_seed(42)
    )
    
    print(f"[DATA] æ•°æ®åˆ’åˆ†: è®­ç»ƒ={len(train_set)}, éªŒè¯={len(val_set)}, æµ‹è¯•={len(test_set)}")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    batch_size = cfg["train"]["batch_size"]
    train_loader = DataLoader(
        train_set, batch_size=batch_size, shuffle=True, collate_fn=collate_fn
    )
    val_loader = DataLoader(
        val_set, batch_size=batch_size, shuffle=False, collate_fn=collate_fn
    )
    test_loader = DataLoader(
        test_set, batch_size=batch_size, shuffle=False, collate_fn=collate_fn
    )
    
    # æ•°æ®é›†ä¿¡æ¯
    dataset_info = {
        'tab_dim': dataset.items[0]["tabular"].shape[0],
        'spec_len': len(wave_cols),
        'num_classes': len(set(item["label"] for item in dataset.items)),
        'class_distribution': pd.Series([item["label"] for item in dataset.items]).value_counts().to_dict()
    }
    
    print(f"[DATA] æ•°æ®é›†ä¿¡æ¯:")
    print(f"   - è¡¨æ ¼ç‰¹å¾ç»´åº¦: {dataset_info['tab_dim']}")
    print(f"   - å…‰è°±é•¿åº¦: {dataset_info['spec_len']}")
    print(f"   - ç±»åˆ«æ•°: {dataset_info['num_classes']}")
    print(f"   - ç±»åˆ«åˆ†å¸ƒ: {dataset_info['class_distribution']}")
    
    return train_loader, val_loader, test_loader, dataset_info


def train_single_model(
    cfg: dict,
    train_loader: DataLoader,
    val_loader: DataLoader,
    test_loader: DataLoader,
    dataset_info: dict,
    model_name: str = None
) -> EnhancedTrainer:
    """
    è®­ç»ƒå•ä¸ªæ¨¡å‹
    
    Args:
        cfg: é…ç½®å­—å…¸
        train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
        val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
        test_loader: æµ‹è¯•æ•°æ®åŠ è½½å™¨
        dataset_info: æ•°æ®é›†ä¿¡æ¯
        model_name: æ¨¡å‹åç§°ï¼ˆå¯é€‰ï¼Œè¦†ç›–é…ç½®ä¸­çš„åç§°ï¼‰
    
    Returns:
        è®­ç»ƒå¥½çš„è®­ç»ƒå™¨
    """
    # ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹åç§°æˆ–é…ç½®ä¸­çš„åç§°
    if model_name:
        cfg["model"]["name"] = model_name

    # ç¡®ä¿æ¨¡å‹çš„ç±»åˆ«æ•°ä¸æ•°æ®é›†ä¸€è‡´ï¼ˆé¿å… config ä¸­ num_classes é…é”™ï¼‰
    if "num_classes" in dataset_info:
        cfg.setdefault("model", {})
        cfg["model"]["num_classes"] = int(dataset_info["num_classes"])
    
    # æ„å»ºæ¨¡å‹
    model = build_model(cfg, dataset_info['tab_dim'], dataset_info['spec_len'])
    
    # åˆ›å»ºè®­ç»ƒå™¨ï¼ˆç¡®ä¿è¶…å‚æ•°ä¸ºæ•°å€¼ç±»å‹ï¼‰
    lr_value = float(cfg["train"].get("lr", 1e-3))
    wd_raw = cfg["train"].get("weight_decay", 1e-4)
    weight_decay_value = float(wd_raw) if wd_raw is not None else 0.0
    use_embedding_input = cfg.get("data", {}).get("use_embedding", False)

    trainer = EnhancedTrainer(
        model=model,
        model_name=cfg["model"]["name"],
        device=torch.device("cuda" if torch.cuda.is_available() else "cpu"),
        lr=lr_value,
        weight_decay=weight_decay_value,
        save_dir=cfg["train"].get("save_dir", "results"),
        enable_visualization=cfg.get("visualization", {}).get("enable", True),
        enable_interpretability=cfg.get("interpretability", {}).get("enable", True),
        use_embedding_input=use_embedding_input,
    )
    
    # æ‰“å°æ¨¡å‹ä¿¡æ¯
    model_summary = trainer.get_model_summary()
    print(f"\n[MODEL] æ¨¡å‹æ‘˜è¦:")
    print(f"   - æ¨¡å‹åç§°: {model_summary['model_name']}")
    print(f"   - æ€»å‚æ•°æ•°: {model_summary['total_parameters']:,}")
    print(f"   - å¯è®­ç»ƒå‚æ•°: {model_summary['trainable_parameters']:,}")
    print(f"   - æ¨¡å‹å¤§å°: {model_summary['model_size_mb']:.2f} MB")
    print(f"   - è®¾å¤‡: {model_summary['device']}")
    
    # è®­ç»ƒæ¨¡å‹
    training_result = trainer.train(
        train_loader=train_loader,
        val_loader=val_loader,
        epochs=cfg["train"]["epochs"],
        early_stopping_patience=cfg["train"].get("early_stopping_patience", 10),
        save_best=True
    )
    
    # æµ‹è¯•æ¨¡å‹
    print(f"\n[TEST] æµ‹è¯• {cfg['model']['name']}...")
    test_result = trainer.evaluate(test_loader, generate_plots=True)
    
    # ä¿å­˜è¯¦ç»†ç»“æœï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
    results_path = trainer.save_dir / "results.json"
    with open(results_path, 'w', encoding='utf-8') as f:
        import json
        json.dump({
            'model_name': cfg["model"]["name"],
            'training_result': training_result,
            'test_result': {
                'metrics': test_result['metrics'],
                'classification_report': test_result['classification_report']
            },
            'model_summary': model_summary
        }, f, indent=2, ensure_ascii=False)
    
    # ä¿å­˜ç»Ÿä¸€æ ¼å¼çš„æŒ‡æ ‡æ‘˜è¦ï¼ˆä¾›å®éªŒæ±‡æ€»è„šæœ¬ä½¿ç”¨ï¼‰
    metrics_summary = {
        'model_name': cfg["model"]["name"],
        'best_val_auc': training_result.get('best_val_auc', None),
        'best_epoch': training_result.get('best_epoch', None),
        'total_time': training_result.get('total_time', None),
        'final_val_auc': training_result.get('val_history', {}).get('auc', [None])[-1] if training_result.get('val_history', {}).get('auc') else None,
        'final_val_acc': training_result.get('val_history', {}).get('acc', [None])[-1] if training_result.get('val_history', {}).get('acc') else None,
        'final_val_f1': training_result.get('val_history', {}).get('f1', [None])[-1] if training_result.get('val_history', {}).get('f1') else None,
        'test_auc': test_result['metrics'].get('auc', None),
        'test_acc': test_result['metrics'].get('acc', None),
        'test_f1': test_result['metrics'].get('f1', None),
        'test_sensitivity@90%spec': test_result['metrics'].get('sensitivity@90%spec', None),
    }
    
    metrics_summary_path = trainer.save_dir / "metrics_summary.json"
    with open(metrics_summary_path, 'w', encoding='utf-8') as f:
        json.dump(metrics_summary, f, indent=2, ensure_ascii=False)
    
    print(f"[OK] {cfg['model']['name']} è®­ç»ƒå®Œæˆ!")
    print(f"[RESULT] æµ‹è¯•AUC: {test_result['metrics']['auc']:.4f}")
    print(f"[RESULT] æµ‹è¯•å‡†ç¡®ç‡: {test_result['metrics']['acc']:.4f}")
    
    return trainer


def train_all_models(
    cfg: dict,
    train_loader: DataLoader,
    val_loader: DataLoader,
    test_loader: DataLoader,
    dataset_info: dict
) -> list:
    """
    è®­ç»ƒæ‰€æœ‰æ¨¡å‹å¹¶è¿›è¡Œæ¯”è¾ƒ
    
    Args:
        cfg: é…ç½®å­—å…¸
        train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
        val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
        test_loader: æµ‹è¯•æ•°æ®åŠ è½½å™¨
        dataset_info: æ•°æ®é›†ä¿¡æ¯
    
    Returns:
        è®­ç»ƒå™¨åˆ—è¡¨
    """
    print(f"\nğŸš€ å¼€å§‹è®­ç»ƒæ‰€æœ‰æ¨¡å‹...")
    print("=" * 60)
    
    # å®šä¹‰è¦è®­ç»ƒçš„æ¨¡å‹
    models_to_train = cfg.get("models_to_train", [
        "AttentionMultimodal",
        "ConcatFusion", 
        "TFTMultimodal"
    ])
    
    trainers = []
    
    for model_name in models_to_train:
        print(f"\n{'='*20} è®­ç»ƒ {model_name} {'='*20}")
        
        try:
            trainer = train_single_model(
                cfg=cfg,
                train_loader=train_loader,
                val_loader=val_loader,
                test_loader=test_loader,
                dataset_info=dataset_info,
                model_name=model_name
            )
            trainers.append(trainer)
            
        except Exception as e:
            print(f"[ERROR] è®­ç»ƒ {model_name} å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    # æ¨¡å‹æ¯”è¾ƒ
    if len(trainers) > 1:
        print(f"\nğŸ”„ å¼€å§‹æ¨¡å‹æ¯”è¾ƒ...")
        comparison_result = compare_models(
            trainers=trainers,
            test_loader=test_loader,
            save_dir=cfg["train"].get("save_dir", "results") + "/comparison"
        )
        
        print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {comparison_result['best_model']}")
        print(f"[RESULT] æœ€ä½³AUC: {comparison_result['best_auc']:.4f}")
        
        # ä¿å­˜æ¯”è¾ƒç»“æœ
        comparison_path = Path(cfg["train"].get("save_dir", "results")) / "comparison" / "comparison_summary.json"
        with open(comparison_path, 'w', encoding='utf-8') as f:
            import json
            json.dump({
                'best_model': comparison_result['best_model'],
                'best_auc': comparison_result['best_auc'],
                'metrics_comparison': comparison_result['metrics'].to_dict()
            }, f, indent=2, ensure_ascii=False)
    
    return trainers


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="å¢å¼ºç‰ˆå¤šæ¨¡æ€æ¨¡å‹è®­ç»ƒè„šæœ¬")
    parser.add_argument("--config", type=str, required=True, help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--model", type=str, default=None, help="æŒ‡å®šå•ä¸ªæ¨¡å‹åç§°")
    parser.add_argument("--train-all", action="store_true", help="è®­ç»ƒæ‰€æœ‰æ¨¡å‹")
    parser.add_argument("--eval-only", type=str, default=None, help="ä»…è¯„ä¼°æŒ‡å®šæ¨¡å‹")
    
    args = parser.parse_args()
    
    print("ğŸš€ å¢å¼ºç‰ˆå¤šæ¨¡æ€æ¨¡å‹è®­ç»ƒç³»ç»Ÿ")
    print("=" * 60)
    
    # åŠ è½½é…ç½®
    cfg = load_config(args.config)
    print(f"ğŸ“‹ é…ç½®æ–‡ä»¶: {args.config}")
    
    # å‡†å¤‡æ•°æ®
    train_loader, val_loader, test_loader, dataset_info = prepare_data(cfg)
    
    if args.eval_only:
        # ä»…è¯„ä¼°æ¨¡å¼
        print(f"\n[EVAL] ä»…è¯„ä¼°æ¨¡å¼: {args.eval_only}")
        model = build_model(cfg, dataset_info['tab_dim'], dataset_info['spec_len'])
        trainer = EnhancedTrainer(
            model=model,
            model_name=args.eval_only,
            device=torch.device("cuda" if torch.cuda.is_available() else "cpu"),
            save_dir=cfg["train"].get("save_dir", "results")
        )
        trainer.load_model()
        result = trainer.evaluate(test_loader)
        print(f"[RESULT] è¯„ä¼°ç»“æœ: {result['metrics']}")
        
    elif args.train_all:
        # è®­ç»ƒæ‰€æœ‰æ¨¡å‹
        trainers = train_all_models(cfg, train_loader, val_loader, test_loader, dataset_info)
        
    else:
        # è®­ç»ƒå•ä¸ªæ¨¡å‹
        model_name = args.model or cfg["model"]["name"]
        trainer = train_single_model(
            cfg=cfg,
            train_loader=train_loader,
            val_loader=val_loader,
            test_loader=test_loader,
            dataset_info=dataset_info,
            model_name=model_name
        )
    
    print(f"\nğŸ‰ è®­ç»ƒå®Œæˆ!")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {cfg['train'].get('save_dir', 'results')}")


if __name__ == "__main__":
    main()

