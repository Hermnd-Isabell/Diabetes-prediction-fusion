#!/usr/bin/env python3
"""
å¢å¼ºç‰ˆä¸»è®­ç»ƒè„šæœ¬ - æ”¯æŒå››ä¸ªæ¨¡å‹å¹¶åŒ…å«ä¸°å¯Œçš„å¯è§†åŒ–å’Œå¯è§£é‡Šæ€§åˆ†æ

æ”¯æŒçš„æ¨¡å‹:
- AttentionMultimodal (æ³¨æ„åŠ›æœºåˆ¶)
- Baseline (ConcatFusion, EnsembleFusion)  
- TFTMultimodal (æ—¶åºèåˆTransformer)

åŠŸèƒ½ç‰¹æ€§:
- å¤šæ¨¡å‹è®­ç»ƒå’Œå¯¹æ¯”
- ä¸°å¯Œçš„å¯è§†åŒ–å±•ç¤º
- å¯è§£é‡Šæ€§åˆ†æ
- æ€§èƒ½æŒ‡æ ‡è·Ÿè¸ª
- æ¨¡å‹ä¿å­˜å’ŒåŠ è½½
"""

import argparse
import yaml
import torch
import numpy as np
import pandas as pd
from pathlib import Path
from torch.utils.data import DataLoader, random_split
import warnings

# å¯¼å…¥æ•°æ®é›†å’Œè®­ç»ƒå™¨
from datasets.raman_dataset import RamanDataset, collate_fn, preprocess_spectrum
from trainers.enhanced_trainer import EnhancedTrainer, compare_models

# å¯¼å…¥æ‰€æœ‰æ¨¡å‹
from models.Baseline import SpectraEncoder, TabularEncoder, ConcatFusion, EnsembleFusion
from models.attention_models import AttentionMultimodal
from models.tft_models import TFTMultimodal
from models.enhanced_mmtm_models import EnhancedMMTMFusion

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings('ignore')


def load_config(config_path: str) -> dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    with open(config_path, "r", encoding='utf-8') as f:
        return yaml.safe_load(f)


def build_model(cfg: dict, tab_dim: int, spec_len: int) -> torch.nn.Module:
    """
    æ ¹æ®é…ç½®æ„å»ºæ¨¡å‹
    
    Args:
        cfg: é…ç½®å­—å…¸
        tab_dim: è¡¨æ ¼ç‰¹å¾ç»´åº¦
        spec_len: å…‰è°±é•¿åº¦
    
    Returns:
        æ„å»ºçš„æ¨¡å‹
    """
    model_name = cfg["model"]["name"]
    num_classes = cfg["model"]["num_classes"]
    
    print(f"ğŸ—ï¸  æ„å»ºæ¨¡å‹: {model_name}")
    
    if model_name == "Spectra-only":
        return SpectraEncoder(input_dim=spec_len, hidden_dim=256)
    
    elif model_name == "Clinical-only":
        return TabularEncoder(input_dim=tab_dim, hidden_dim=128)
    
    elif model_name == "ConcatFusion":
        return ConcatFusion(spec_dim=256, clin_dim=128)
    
    elif model_name == "EnsembleFusion":
        return EnsembleFusion(spec_dim=256, clin_dim=128)
    
    elif model_name == "AttentionMultimodal":
        # å…¼å®¹æ—§é…ç½®ä¸­çš„ fusion å–å€¼
        fusion_cfg = cfg["model"].get("fusion", "enhanced_cross")
        fusion_map = {
            "cross": "enhanced_cross",
            "enhanced_cross": "enhanced_cross",
            "concat": "concat"
        }
        fusion_type = fusion_map.get(fusion_cfg, fusion_cfg)

        return AttentionMultimodal(
            spec_embedding_dim=cfg["model"].get("spec_emb", 256),
            tab_embedding_dim=cfg["model"].get("tab_emb", 128),
            num_classes=num_classes,
            fusion_type=fusion_type,
            tab_dim=tab_dim
        )
    
    elif model_name == "TFTMultimodal":
        return TFTMultimodal(
            tab_dim=tab_dim,
            spec_len=spec_len,
            spec_emb=cfg["model"].get("spec_emb", 256),
            tab_emb=cfg["model"].get("tab_emb", 128),
            num_classes=num_classes
        )
    
    
    elif model_name == "EnhancedMMTM":
        return EnhancedMMTMFusion(
            spec_embedding_dim=cfg["model"].get("spec_emb", 256),
            tab_embedding_dim=cfg["model"].get("tab_emb", 128),
            num_classes=num_classes,
            mmtm_bottleneck=cfg["model"].get("mmtm_bottleneck", 128),
            num_attention_heads=cfg["model"].get("num_attention_heads", 8),
            fusion_strategy=cfg["model"].get("fusion_strategy", "hierarchical"),
            enable_uncertainty=cfg["model"].get("enable_uncertainty", True)
        )
    
    else:
        raise ValueError(f"âŒ æœªçŸ¥æ¨¡å‹åç§°: {model_name}")


def prepare_data(cfg: dict) -> tuple:
    """
    å‡†å¤‡æ•°æ®é›†
    
    Args:
        cfg: é…ç½®å­—å…¸
    
    Returns:
        (train_loader, val_loader, test_loader, dataset_info)
    """
    print("ğŸ“Š å‡†å¤‡æ•°æ®é›†...")
    
    # æ•°æ®è·¯å¾„
    spectra_csv = cfg["data"]["spectra_csv"]
    clinical_csv = cfg["data"]["clinical_csv"]
    
    # è¯»å–å…‰è°±æ•°æ®è·å–æ³¢é•¿åˆ—
    spectra_df = pd.read_csv(spectra_csv, sep=None, engine="python")
    wave_cols = [c for c in spectra_df.columns if c not in ["Sample", "Group"]]
    
    # åˆ›å»ºæ•°æ®é›†
    dataset = RamanDataset(
        spectra_csv=spectra_csv,
        clinical_csv=clinical_csv,
        wave_cols=wave_cols,
        label_col=cfg["data"].get("label_col", "Group"),
        preprocess_fn=preprocess_spectrum,
        min_scans=1,
        max_scans=cfg["data"].get("max_scans", 180)
    )
    
    print(f"âœ… æ•°æ®é›†åŠ è½½å®Œæˆ: {len(dataset)} ä¸ªæ ·æœ¬")
    
    # æ•°æ®åˆ’åˆ†
    train_ratio = cfg["data"].get("train_ratio", 0.7)
    val_ratio = cfg["data"].get("val_ratio", 0.15)
    test_ratio = cfg["data"].get("test_ratio", 0.15)
    
    # ç¡®ä¿æ¯”ä¾‹å’Œä¸º1
    total_ratio = train_ratio + val_ratio + test_ratio
    train_ratio /= total_ratio
    val_ratio /= total_ratio
    test_ratio /= total_ratio
    
    train_size = int(train_ratio * len(dataset))
    val_size = int(val_ratio * len(dataset))
    test_size = len(dataset) - train_size - val_size
    
    train_set, val_set, test_set = random_split(
        dataset, [train_size, val_size, test_size],
        generator=torch.Generator().manual_seed(42)
    )
    
    print(f"ğŸ“Š æ•°æ®åˆ’åˆ†: è®­ç»ƒ={len(train_set)}, éªŒè¯={len(val_set)}, æµ‹è¯•={len(test_set)}")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    batch_size = cfg["train"]["batch_size"]
    train_loader = DataLoader(
        train_set, batch_size=batch_size, shuffle=True, collate_fn=collate_fn
    )
    val_loader = DataLoader(
        val_set, batch_size=batch_size, shuffle=False, collate_fn=collate_fn
    )
    test_loader = DataLoader(
        test_set, batch_size=batch_size, shuffle=False, collate_fn=collate_fn
    )
    
    # æ•°æ®é›†ä¿¡æ¯
    dataset_info = {
        'tab_dim': dataset.items[0]["tabular"].shape[0],
        'spec_len': len(wave_cols),
        'num_classes': len(set(item["label"] for item in dataset.items)),
        'class_distribution': pd.Series([item["label"] for item in dataset.items]).value_counts().to_dict()
    }
    
    print(f"ğŸ“Š æ•°æ®é›†ä¿¡æ¯:")
    print(f"   â€¢ è¡¨æ ¼ç‰¹å¾ç»´åº¦: {dataset_info['tab_dim']}")
    print(f"   â€¢ å…‰è°±é•¿åº¦: {dataset_info['spec_len']}")
    print(f"   â€¢ ç±»åˆ«æ•°: {dataset_info['num_classes']}")
    print(f"   â€¢ ç±»åˆ«åˆ†å¸ƒ: {dataset_info['class_distribution']}")
    
    return train_loader, val_loader, test_loader, dataset_info


def train_single_model(
    cfg: dict,
    train_loader: DataLoader,
    val_loader: DataLoader,
    test_loader: DataLoader,
    dataset_info: dict,
    model_name: str = None
) -> EnhancedTrainer:
    """
    è®­ç»ƒå•ä¸ªæ¨¡å‹
    
    Args:
        cfg: é…ç½®å­—å…¸
        train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
        val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
        test_loader: æµ‹è¯•æ•°æ®åŠ è½½å™¨
        dataset_info: æ•°æ®é›†ä¿¡æ¯
        model_name: æ¨¡å‹åç§°ï¼ˆå¯é€‰ï¼Œè¦†ç›–é…ç½®ä¸­çš„åç§°ï¼‰
    
    Returns:
        è®­ç»ƒå¥½çš„è®­ç»ƒå™¨
    """
    # ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹åç§°æˆ–é…ç½®ä¸­çš„åç§°
    if model_name:
        cfg["model"]["name"] = model_name
    
    # æ„å»ºæ¨¡å‹
    model = build_model(cfg, dataset_info['tab_dim'], dataset_info['spec_len'])
    
    # åˆ›å»ºè®­ç»ƒå™¨ï¼ˆç¡®ä¿è¶…å‚æ•°ä¸ºæ•°å€¼ç±»å‹ï¼‰
    lr_value = float(cfg["train"].get("lr", 1e-3))
    wd_raw = cfg["train"].get("weight_decay", 1e-4)
    weight_decay_value = float(wd_raw) if wd_raw is not None else 0.0

    trainer = EnhancedTrainer(
        model=model,
        model_name=cfg["model"]["name"],
        device=torch.device("cuda" if torch.cuda.is_available() else "cpu"),
        lr=lr_value,
        weight_decay=weight_decay_value,
        save_dir=cfg["train"].get("save_dir", "results"),
        enable_visualization=cfg.get("visualization", {}).get("enable", True),
        enable_interpretability=cfg.get("interpretability", {}).get("enable", True)
    )
    
    # æ‰“å°æ¨¡å‹ä¿¡æ¯
    model_summary = trainer.get_model_summary()
    print(f"\nğŸ“Š æ¨¡å‹æ‘˜è¦:")
    print(f"   â€¢ æ¨¡å‹åç§°: {model_summary['model_name']}")
    print(f"   â€¢ æ€»å‚æ•°æ•°: {model_summary['total_parameters']:,}")
    print(f"   â€¢ å¯è®­ç»ƒå‚æ•°: {model_summary['trainable_parameters']:,}")
    print(f"   â€¢ æ¨¡å‹å¤§å°: {model_summary['model_size_mb']:.2f} MB")
    print(f"   â€¢ è®¾å¤‡: {model_summary['device']}")
    
    # è®­ç»ƒæ¨¡å‹
    training_result = trainer.train(
        train_loader=train_loader,
        val_loader=val_loader,
        epochs=cfg["train"]["epochs"],
        early_stopping_patience=cfg["train"].get("early_stopping_patience", 10),
        save_best=True
    )
    
    # æµ‹è¯•æ¨¡å‹
    print(f"\nğŸ” æµ‹è¯• {cfg['model']['name']}...")
    test_result = trainer.evaluate(test_loader, generate_plots=True)
    
    # ä¿å­˜ç»“æœ
    results_path = trainer.save_dir / "results.json"
    with open(results_path, 'w', encoding='utf-8') as f:
        import json
        json.dump({
            'model_name': cfg["model"]["name"],
            'training_result': training_result,
            'test_result': {
                'metrics': test_result['metrics'],
                'classification_report': test_result['classification_report']
            },
            'model_summary': model_summary
        }, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… {cfg['model']['name']} è®­ç»ƒå®Œæˆ!")
    print(f"ğŸ“Š æµ‹è¯•AUC: {test_result['metrics']['auc']:.4f}")
    print(f"ğŸ“Š æµ‹è¯•å‡†ç¡®ç‡: {test_result['metrics']['acc']:.4f}")
    
    return trainer


def train_all_models(
    cfg: dict,
    train_loader: DataLoader,
    val_loader: DataLoader,
    test_loader: DataLoader,
    dataset_info: dict
) -> list:
    """
    è®­ç»ƒæ‰€æœ‰æ¨¡å‹å¹¶è¿›è¡Œæ¯”è¾ƒ
    
    Args:
        cfg: é…ç½®å­—å…¸
        train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
        val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
        test_loader: æµ‹è¯•æ•°æ®åŠ è½½å™¨
        dataset_info: æ•°æ®é›†ä¿¡æ¯
    
    Returns:
        è®­ç»ƒå™¨åˆ—è¡¨
    """
    print(f"\nğŸš€ å¼€å§‹è®­ç»ƒæ‰€æœ‰æ¨¡å‹...")
    print("=" * 60)
    
    # å®šä¹‰è¦è®­ç»ƒçš„æ¨¡å‹
    models_to_train = cfg.get("models_to_train", [
        "AttentionMultimodal",
        "ConcatFusion", 
        "TFTMultimodal"
    ])
    
    trainers = []
    
    for model_name in models_to_train:
        print(f"\n{'='*20} è®­ç»ƒ {model_name} {'='*20}")
        
        try:
            trainer = train_single_model(
                cfg=cfg,
                train_loader=train_loader,
                val_loader=val_loader,
                test_loader=test_loader,
                dataset_info=dataset_info,
                model_name=model_name
            )
            trainers.append(trainer)
            
        except Exception as e:
            print(f"âŒ è®­ç»ƒ {model_name} å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    # æ¨¡å‹æ¯”è¾ƒ
    if len(trainers) > 1:
        print(f"\nğŸ”„ å¼€å§‹æ¨¡å‹æ¯”è¾ƒ...")
        comparison_result = compare_models(
            trainers=trainers,
            test_loader=test_loader,
            save_dir=cfg["train"].get("save_dir", "results") + "/comparison"
        )
        
        print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {comparison_result['best_model']}")
        print(f"ğŸ“Š æœ€ä½³AUC: {comparison_result['best_auc']:.4f}")
        
        # ä¿å­˜æ¯”è¾ƒç»“æœ
        comparison_path = Path(cfg["train"].get("save_dir", "results")) / "comparison" / "comparison_summary.json"
        with open(comparison_path, 'w', encoding='utf-8') as f:
            import json
            json.dump({
                'best_model': comparison_result['best_model'],
                'best_auc': comparison_result['best_auc'],
                'metrics_comparison': comparison_result['metrics'].to_dict()
            }, f, indent=2, ensure_ascii=False)
    
    return trainers


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="å¢å¼ºç‰ˆå¤šæ¨¡æ€æ¨¡å‹è®­ç»ƒè„šæœ¬")
    parser.add_argument("--config", type=str, required=True, help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--model", type=str, default=None, help="æŒ‡å®šå•ä¸ªæ¨¡å‹åç§°")
    parser.add_argument("--train-all", action="store_true", help="è®­ç»ƒæ‰€æœ‰æ¨¡å‹")
    parser.add_argument("--eval-only", type=str, default=None, help="ä»…è¯„ä¼°æŒ‡å®šæ¨¡å‹")
    
    args = parser.parse_args()
    
    print("ğŸš€ å¢å¼ºç‰ˆå¤šæ¨¡æ€æ¨¡å‹è®­ç»ƒç³»ç»Ÿ")
    print("=" * 60)
    
    # åŠ è½½é…ç½®
    cfg = load_config(args.config)
    print(f"ğŸ“‹ é…ç½®æ–‡ä»¶: {args.config}")
    
    # å‡†å¤‡æ•°æ®
    train_loader, val_loader, test_loader, dataset_info = prepare_data(cfg)
    
    if args.eval_only:
        # ä»…è¯„ä¼°æ¨¡å¼
        print(f"\nğŸ” ä»…è¯„ä¼°æ¨¡å¼: {args.eval_only}")
        model = build_model(cfg, dataset_info['tab_dim'], dataset_info['spec_len'])
        trainer = EnhancedTrainer(
            model=model,
            model_name=args.eval_only,
            device=torch.device("cuda" if torch.cuda.is_available() else "cpu"),
            save_dir=cfg["train"].get("save_dir", "results")
        )
        trainer.load_model()
        result = trainer.evaluate(test_loader)
        print(f"ğŸ“Š è¯„ä¼°ç»“æœ: {result['metrics']}")
        
    elif args.train_all:
        # è®­ç»ƒæ‰€æœ‰æ¨¡å‹
        trainers = train_all_models(cfg, train_loader, val_loader, test_loader, dataset_info)
        
    else:
        # è®­ç»ƒå•ä¸ªæ¨¡å‹
        model_name = args.model or cfg["model"]["name"]
        trainer = train_single_model(
            cfg=cfg,
            train_loader=train_loader,
            val_loader=val_loader,
            test_loader=test_loader,
            dataset_info=dataset_info,
            model_name=model_name
        )
    
    print(f"\nğŸ‰ è®­ç»ƒå®Œæˆ!")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {cfg['train'].get('save_dir', 'results')}")


if __name__ == "__main__":
    main()

