#!/usr/bin/env python3
"""
å‡æ•°æ®è®­ç»ƒä¸»å‡½æ•° - ä½¿ç”¨ç°æœ‰è®­ç»ƒç³»ç»Ÿè®­ç»ƒå‡æ•°æ®

è¿™ä¸ªè„šæœ¬å…è®¸ä½ ä½¿ç”¨ç°æœ‰çš„è®­ç»ƒå™¨å’Œmainå‡½æ•°æ¥è®­ç»ƒæ¨¡å‹ï¼Œ
ä½†ä½¿ç”¨å‡æ•°æ®è€Œä¸æ˜¯çœŸå®æ•°æ®ï¼Œéå¸¸é€‚åˆæµ‹è¯•å’ŒéªŒè¯ã€‚

ä½¿ç”¨æ–¹æ³•:
1. ä½¿ç”¨é»˜è®¤é…ç½®: python fake_data_main.py
2. æŒ‡å®šé…ç½®æ–‡ä»¶: python fake_data_main.py --config configs/fake_data_config.yaml
3. è®­ç»ƒå•ä¸ªæ¨¡å‹: python fake_data_main.py --model AttentionMultimodal
4. è®­ç»ƒæ‰€æœ‰æ¨¡å‹: python fake_data_main.py --train-all
5. è‡ªå®šä¹‰å‚æ•°: python fake_data_main.py --samples 100 --epochs 10 --batch-size 4
"""

import argparse
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from fake_data_adapter import FakeDataAdapter


def main():
    """ä¸»å‡½æ•° - ä½¿ç”¨å‡æ•°æ®è®­ç»ƒæ¨¡å‹"""
    parser = argparse.ArgumentParser(
        description="ä½¿ç”¨å‡æ•°æ®è®­ç»ƒå¤šæ¨¡æ€æ¨¡å‹",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # ä½¿ç”¨é»˜è®¤é…ç½®è®­ç»ƒAttentionMultimodal
  python fake_data_main.py
  
  # ä½¿ç”¨æŒ‡å®šé…ç½®æ–‡ä»¶
  python fake_data_main.py --config configs/fake_data_config.yaml
  
  # è®­ç»ƒå•ä¸ªæ¨¡å‹
  python fake_data_main.py --model AttentionMultimodal
  
  # è®­ç»ƒæ‰€æœ‰æ¨¡å‹
  python fake_data_main.py --train-all
  
  # è‡ªå®šä¹‰å‚æ•°
  python fake_data_main.py --samples 100 --epochs 10 --batch-size 4
  
  # å¿«é€Ÿæµ‹è¯•ï¼ˆå°æ•°æ®é‡ï¼‰
  python fake_data_main.py --samples 50 --epochs 5 --batch-size 4
        """
    )
    
    # é…ç½®æ–‡ä»¶å‚æ•°
    parser.add_argument(
        "--config", 
        type=str, 
        default="configs/fake_data_config.yaml",
        help="é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: configs/fake_data_config.yamlï¼‰"
    )
    
    # æ¨¡å‹é€‰æ‹©å‚æ•°
    parser.add_argument(
        "--model", 
        type=str, 
        default=None,
        choices=["AttentionMultimodal", "ConcatFusion", "EnsembleFusion", "TFTMultimodal", "EnhancedMMTMFusion", "BaselineMultimodal"],
        help="æŒ‡å®šå•ä¸ªæ¨¡å‹åç§°"
    )
    parser.add_argument(
        "--train-all", 
        action="store_true",
        help="è®­ç»ƒæ‰€æœ‰æ¨¡å‹"
    )
    
    # æ•°æ®å‚æ•°
    parser.add_argument(
        "--samples", 
        type=int, 
        default=None,
        help="å‡æ•°æ®æ ·æœ¬æ•°é‡"
    )
    parser.add_argument(
        "--scans", 
        type=int, 
        default=None,
        help="æ¯ä¸ªæ ·æœ¬çš„æ‰«ææ¬¡æ•°"
    )
    parser.add_argument(
        "--wavelengths", 
        type=int, 
        default=None,
        help="å…‰è°±æ³¢é•¿æ•°é‡"
    )
    parser.add_argument(
        "--features", 
        type=int, 
        default=None,
        help="è¡¨æ ¼ç‰¹å¾æ•°é‡"
    )
    parser.add_argument(
        "--classes", 
        type=int, 
        default=None,
        help="åˆ†ç±»ç±»åˆ«æ•°"
    )
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument(
        "--epochs", 
        type=int, 
        default=None,
        help="è®­ç»ƒè½®æ•°"
    )
    parser.add_argument(
        "--batch-size", 
        type=int, 
        default=None,
        help="æ‰¹æ¬¡å¤§å°"
    )
    parser.add_argument(
        "--lr", 
        type=float, 
        default=None,
        help="å­¦ä¹ ç‡"
    )
    parser.add_argument(
        "--weight-decay", 
        type=float, 
        default=None,
        help="æƒé‡è¡°å‡"
    )
    
    # å…¶ä»–å‚æ•°
    parser.add_argument(
        "--save-dir", 
        type=str, 
        default=None,
        help="ç»“æœä¿å­˜ç›®å½•"
    )
    parser.add_argument(
        "--device", 
        type=str, 
        default="auto",
        choices=["auto", "cuda", "cpu"],
        help="è®­ç»ƒè®¾å¤‡"
    )
    parser.add_argument(
        "--seed", 
        type=int, 
        default=None,
        help="éšæœºç§å­"
    )
    parser.add_argument(
        "--verbose", 
        action="store_true",
        help="è¯¦ç»†è¾“å‡º"
    )
    
    args = parser.parse_args()
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    config_path = Path(args.config)
    if not config_path.exists():
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        print(f"ğŸ’¡ ä½¿ç”¨é»˜è®¤é…ç½®...")
        config_path = None
    
    print("ğŸš€ ä½¿ç”¨å‡æ•°æ®è®­ç»ƒå¤šæ¨¡æ€æ¨¡å‹")
    print("=" * 60)
    
    # åˆ›å»ºé€‚é…å™¨
    adapter = FakeDataAdapter(config_path=str(config_path) if config_path else None)
    
    # æ›´æ–°é…ç½®ï¼ˆå¦‚æœé€šè¿‡å‘½ä»¤è¡Œå‚æ•°æŒ‡å®šäº†å‚æ•°ï¼‰
    if args.samples:
        adapter.config["data"]["num_samples"] = args.samples
    if args.scans:
        adapter.config["data"]["num_scans"] = args.scans
    if args.wavelengths:
        adapter.config["data"]["num_wavelengths"] = args.wavelengths
    if args.features:
        adapter.config["data"]["num_features"] = args.features
    if args.classes:
        adapter.config["data"]["num_classes"] = args.classes
        adapter.config["model"]["num_classes"] = args.classes
    
    if args.epochs:
        adapter.config["train"]["epochs"] = args.epochs
    if args.batch_size:
        adapter.config["train"]["batch_size"] = args.batch_size
    if args.lr:
        adapter.config["train"]["lr"] = args.lr
    if args.weight_decay:
        adapter.config["train"]["weight_decay"] = args.weight_decay
    
    if args.save_dir:
        adapter.config["train"]["save_dir"] = args.save_dir
    if args.seed:
        adapter.config["experiment"]["random_seed"] = args.seed
    
    # è®¾ç½®éšæœºç§å­
    if args.seed:
        import torch
        import numpy as np
        torch.manual_seed(args.seed)
        np.random.seed(args.seed)
    
    # æ‰“å°é…ç½®ä¿¡æ¯
    print(f"ğŸ“‹ é…ç½®ä¿¡æ¯:")
    print(f"   â€¢ æ ·æœ¬æ•°é‡: {adapter.config['data']['num_samples']}")
    print(f"   â€¢ æ‰«ææ¬¡æ•°: {adapter.config['data']['num_scans']}")
    print(f"   â€¢ æ³¢é•¿æ•°é‡: {adapter.config['data']['num_wavelengths']}")
    print(f"   â€¢ ç‰¹å¾æ•°é‡: {adapter.config['data']['num_features']}")
    print(f"   â€¢ ç±»åˆ«æ•°é‡: {adapter.config['data']['num_classes']}")
    print(f"   â€¢ è®­ç»ƒè½®æ•°: {adapter.config['train']['epochs']}")
    print(f"   â€¢ æ‰¹æ¬¡å¤§å°: {adapter.config['train']['batch_size']}")
    print(f"   â€¢ å­¦ä¹ ç‡: {adapter.config['train']['lr']}")
    print(f"   â€¢ ä¿å­˜ç›®å½•: {adapter.config['train']['save_dir']}")
    
    if args.verbose:
        print(f"\nğŸ” è¯¦ç»†é…ç½®:")
        import yaml
        print(yaml.dump(adapter.config, default_flow_style=False, allow_unicode=True))
    
    try:
        # å‡†å¤‡æ•°æ®
        train_loader, val_loader, test_loader, dataset_info = adapter.prepare_fake_data()
        
        if args.train_all:
            # è®­ç»ƒæ‰€æœ‰æ¨¡å‹
            print(f"\nğŸš€ å¼€å§‹è®­ç»ƒæ‰€æœ‰æ¨¡å‹...")
            trainers = adapter.train_all_models(train_loader, val_loader, test_loader, dataset_info)
            
            print(f"\nğŸ‰ æ‰€æœ‰æ¨¡å‹è®­ç»ƒå®Œæˆ!")
            print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {adapter.config['train']['save_dir']}")
            
        else:
            # è®­ç»ƒå•ä¸ªæ¨¡å‹
            model_name = args.model or adapter.config["model"]["name"]
            print(f"\nğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹: {model_name}")
            
            trainer = adapter.train_single_model(
                train_loader=train_loader,
                val_loader=val_loader,
                test_loader=test_loader,
                dataset_info=dataset_info,
                model_name=model_name
            )
            
            print(f"\nğŸ‰ æ¨¡å‹è®­ç»ƒå®Œæˆ!")
            print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {adapter.config['train']['save_dir']}")
            
    except KeyboardInterrupt:
        print(f"\nâš ï¸  è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()

